{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import dgl\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch_scatter\n",
    "import torch_sparse\n",
    "import torch_cluster\n",
    "\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "from torch_geometric.nn.conv import MessagePassing\n",
    "from torch_geometric.data import HeteroData\n",
    "\n",
    "from myutils import constructPyGHeteroData\n",
    "\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "from typing import List\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "from operator import itemgetter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "æ•°æ®é›†ä¿¡æ¯ï¼š\n",
    "\n",
    "https://jmcauley.ucsd.edu/data/amazon/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphSage(MessagePassing):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, normalize=True,\n",
    "                 bias=False, **kwargs):\n",
    "        super(GraphSage, self).__init__(**kwargs)\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.normalize = normalize\n",
    "\n",
    "        self.lin_l = None\n",
    "        self.lin_r = None\n",
    "\n",
    "        ############################################################################\n",
    "        # TODO: Your code here!\n",
    "        # Define the layers needed for the message and update functions below.\n",
    "        # self.lin_l is the linear transformation that you apply to embedding\n",
    "        #            for central node.\n",
    "        # self.lin_r is the linear transformation that you apply to aggregated\n",
    "        #            message from neighbors.\n",
    "        # Don't forget the bias!\n",
    "        # Our implementation is ~2 lines, but don't worry if you deviate from this.\n",
    "\n",
    "        ############################################################################\n",
    "\n",
    "        self.lin_l = nn.Linear(in_channels, out_channels, bias=bias)\n",
    "        self.lin_r = nn.Linear(in_channels, out_channels, bias=bias)\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.lin_l.reset_parameters()\n",
    "        self.lin_r.reset_parameters()\n",
    "\n",
    "    def forward(self, x, edge_index, size=None):\n",
    "        \"\"\"\"\"\"\n",
    "        out = self.propagate(edge_index=edge_index, x=(x, x), size=size)\n",
    "        out += self.lin_l(x)\n",
    "        if self.normalize: out = F.normalize(out, p=2)\n",
    "        return out\n",
    "\n",
    "    def message(self, x_j):\n",
    "        return x_j\n",
    "\n",
    "    def aggregate(self, inputs, index, dim_size=None):\n",
    "        # The axis along which to index number of nodes.\n",
    "        node_dim = self.node_dim\n",
    "        out = self.lin_r(torch_scatter.scatter(\n",
    "            inputs, index, dim=node_dim, reduce='mean'))\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graph(num_nodes=716847, num_edges=13954819,\n",
    "      ndata_schemes={'feat': Scheme(shape=(300,), dtype=torch.float32), 'label': Scheme(shape=(100,), dtype=torch.int64), 'train_mask': Scheme(shape=(), dtype=torch.bool), 'val_mask': Scheme(shape=(), dtype=torch.bool), 'test_mask': Scheme(shape=(), dtype=torch.bool)}\n",
    "      edata_schemes={})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class objectview(object):\n",
    "    def __init__(self, d):\n",
    "        self.__dict__ = d\n",
    "# ä½¿ç”¨ObjectViewç±»å¯ä»¥å°†ä¸€ä¸ªå­—å…¸çš„keyè§†ä½œå…¶å±æ€§æ¥è®¿é—®\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "å…³ç³»å†…éƒ¨äº¤äº’å±‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IntraAgg(nn.Module):\n",
    "    \"\"\"\n",
    "    åœ¨æŸä¸€å…³ç³»ä¸‹è¿›è¡Œmessage aggregate\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self, \n",
    "        feature_dim: int, \n",
    "        output_dim: int, \n",
    "        # features: torch.Tensor, # æ€ä¹ˆå¯èƒ½åœ¨ä½ åˆšåˆå§‹åŒ–çš„æ—¶å€™å°±æŠŠfeaturesä¼ è¿›æ¥å‘¢â€¦â€¦ä½ åˆæœªå¿…æ˜¯ç¬¬ä¸€å±‚\n",
    "        # rho: float,\n",
    "        # avg_half_pos_neigh : int, # ç”¨äºå†³å®šoversampleæ—¶é€‰å¤šå°‘ä¸ªåŒç±»èŠ‚ç‚¹\n",
    "        # train_pos_mask: list,\n",
    "        device: torch.device\n",
    "        ) -> None:\n",
    "        \"\"\"\n",
    "        åŸæ–‡å¤ªæ— èµ–ï¼Œå±…ç„¶åœ¨pclayerå¤–é¢å°±æŠŠintraAggå£°æ˜å¥½ï¼Œæ•°æ®ä¹Ÿä¼ è¿›å»äº† \\\\\n",
    "        :param feature_dim: åŸæ•°æ®æ¯ç‚¹çš„ç‰¹å¾ç»´æ•°\n",
    "        :param output_dim: æœ¬å±‚çš„åµŒå…¥ç»´åº¦ï¼Œä¹Ÿå°±æ˜¯è¾“å‡ºç»´åº¦\n",
    "        \"\"\"\n",
    "        super(IntraAgg, self).__init__()\n",
    "        self.feature_dim = feature_dim\n",
    "        self.output_dim = output_dim\n",
    "        # self.features = features # (|N|,feat_dim)\n",
    "        # self.rho = rho # ç”¨äºè·ç¦»å‡½æ•°åˆ¤æ–­çš„ï¼Ÿ\n",
    "        self.device = device\n",
    "        # self.train_pos_mask = train_pos_mask # è¿™æ˜¯ä¸ªåˆ—è¡¨å•Š\n",
    "        # TODO ä¸ºä»€ä¹ˆè¿™ä¸ªçº¿æ€§å±‚ç»´åº¦è®¾ç½®æ€ªæ€ªçš„\n",
    "        self.proj = nn.Linear(2*feature_dim,output_dim)\n",
    "\n",
    "        # åœ¨trainé˜¶æ®µï¼Œè¿™äº›rhoä¸ä¼šè¢«ç”¨ï¼Œä½†ä¼šè¢«æ›´æ–°\n",
    "        self.rho_neg = 0.5\n",
    "        self.rho_pos = 0.5\n",
    "\n",
    "        # self.avg_half_pos_neigh = avg_half_pos_neigh\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        features: torch.Tensor,\n",
    "        batch_center_mask: list,\n",
    "        batch_center_labels: list,\n",
    "        train_pos_mask: list,\n",
    "        rx_list: List[list],\n",
    "        batch_center_logits: torch.Tensor, # (|B|,2)\n",
    "        batch_all_logits: torch.Tensor, # (|BatchAll|,2)\n",
    "        train_pos_logits: torch.Tensor, # (|Pos|,2)\n",
    "        trainIdx2OrderIdx: dict,\n",
    "        orderIdx2trainIdx: dict,\n",
    "        avg_half_pos_neigh: int,\n",
    "        train_flag = True # å¦‚æœæ˜¯testï¼Œæ²¡æ³•é æ ‡ç­¾ä¿¡æ¯æ¥choose\n",
    "    ):\n",
    "        \"\"\"\n",
    "        åœ¨ä¸€å±‚å…³ç³»å†…è¿›è¡Œmessage passing\n",
    "        :param batch_center_mask: æœ¬batchå†…çš„ä¸­å¿ƒç‚¹\n",
    "        :param batch_center_labels: æœ¬batchä¸­å¿ƒç‚¹çš„label\n",
    "        :param rx_list: ç¬¬xå…³ç³»çš„æ‰€æœ‰ä¸­å¿ƒç‚¹çš„é‚»å±…æƒ…å†µ åˆ—è¡¨å¥—åˆ—è¡¨\n",
    "        :param batch_center_logits:\n",
    "        :param batch_all_logits:\n",
    "        :param train_pos_logits:\n",
    "        :param trainIdx2orderIdx: ä»çœŸæ­£çš„node idæŠ•å°„åˆ°rxlistä¸­ç´¢å¼•çš„è¯å…¸\n",
    "        \"\"\"\n",
    "        # æ­¤æ—¶åªæ˜¯train\n",
    "        self.avg_half_pos_neigh = avg_half_pos_neigh\n",
    "        self.train_pos_mask = train_pos_mask\n",
    "        # é¦–å…ˆï¼Œè‚¯å®šè¦å¯¹é‚»å±…è¿›è¡Œundersample\n",
    "        # A(v,u)>0 ä¸” D(v,u) < rho-\n",
    "        rx_list_undersampled = []\n",
    "        out_feats = []\n",
    "        for idx, one_center_logits in enumerate(batch_center_logits):\n",
    "            # å…ˆæŠŠè¿™ä¸ªä¸­å¿ƒç‚¹çš„é‚»å±…ç‚¹çš„logitsæå–å‡ºæ¥\n",
    "            certain_neighbor_logits = batch_all_logits[rx_list[idx]]\n",
    "            # è®¡ç®—distance\n",
    "            distance = torch.abs(certain_neighbor_logits - one_center_logits)[:,0]\n",
    "            howManyNeighbors = distance.shape[0]\n",
    "            sampledNeighbor = (distance.argsort()[0:int(howManyNeighbors / 2) + 1]).tolist()\n",
    "            # å¯¹rho-è¿›è¡Œæ›´æ–° è¿™ä¸ªæ›´æ–°æœ‰ä»€ä¹ˆæ„ä¹‰å—ï¼Ÿ\n",
    "            self.rho_neg = distance(distance.argsort()[int(howManyNeighbors / 2)])\n",
    "            # rx_list_undersampled.append(nearest50Idx)\n",
    "            # è¿™å°±æ˜¯æˆ‘ä»¬é™é‡‡æ ·ä¹‹åçš„é‚»å±…æ ·æœ¬ï¼Œè¿™é‡Œæ˜¯orderIdx\n",
    "        \n",
    "            # label=1çš„æ—¶å€™æ˜¯å°æ ·æœ¬ï¼\n",
    "            choosedSameClassNode = []\n",
    "            if batch_center_labels[idx] == 1:\n",
    "                # TODO è¿™é‡Œçš„ç»´åº¦è‚¯å®šæœ‰ç‚¹é—®é¢˜\n",
    "                distance2 = torch.abs(\n",
    "                    train_pos_logits - one_center_logits)[:, 0]  # è¿™ä¸ªæ—¶å€™å·²ç»flattenäº†\n",
    "                choosedSameClassNode = (distance2.argsort()[\n",
    "                    0:self.avg_half_pos_neigh + 1]).tolist()\n",
    "\n",
    "            # undersampleä¹‹åçš„orderIdxåœ¨undersampledNeighboré‡Œ\n",
    "            # oversampleä¹‹åçš„orderIdxåœ¨choosedSameClassNodeé‡Œ\n",
    "\n",
    "            # è¿›è¡Œaggregateï¼\n",
    "            neighbor_feats = features[itemgetter(*sampledNeighbor)(orderIdx2trainIdx)]\n",
    "            if not choosedSameClassNode == []:\n",
    "                minor_feats = features[np.array(self.train_pos_mask)[choosedSameClassNode]]\n",
    "                neighbor_feats = torch.cat([neighbor_feats,minor_feats],axis=0)\n",
    "\n",
    "            agg_feats = torch.mean(neighbor_feats,axis=0) \n",
    "\n",
    "            # æŠŠå’Œä¸­å¿ƒèŠ‚ç‚¹çš„featè¿›è¡Œcontact\n",
    "            # æ³¨æ„æœ‰ä¸€ä¸ªreshapeï¼\n",
    "            contacted_feat = torch.cat([features[trainIdx2OrderIdx[idx]],agg_feats],axis=0).reshape(1,-1)\n",
    "            # shape: (1,2*h_{l-1})\n",
    "\n",
    "            # è¿›è¡Œçº¿æ€§æ˜ å°„\n",
    "            out_feats.append(F.relu(self.proj(contacted_feat)))\n",
    "        \n",
    "        rx_out_feats = torch.cat(out_feats,axis=0)\n",
    "        return rx_out_feats\n",
    "\n",
    "\n",
    "    def NeighborhoodSamplerForTraining(\n",
    "        self,\n",
    "        batch_center_logits: torch.Tensor,\n",
    "        batch_center_labels: torch.Tensor,\n",
    "        batch_all_logits: torch.Tensor,\n",
    "        train_pos_logits: torch.Tensor,\n",
    "        rx_list: List[list]\n",
    "        ):\n",
    "        \"\"\"\n",
    "        è¿™é‡Œæ˜¯trainingé˜¶æ®µï¼Œæˆ‘ä»¬å°†ä¼šæ ¹æ®é‚»å±…çš„æƒ…å†µæ¥adaptivelyå†³å®šrhoï¼\n",
    "        \"\"\"\n",
    "        # é¦–å…ˆï¼Œè‚¯å®šè¦å¯¹é‚»å±…è¿›è¡Œundersample\n",
    "        # A(v,u)>0 ä¸” D(v,u) < rho-\n",
    "        rx_list_undersampled = []\n",
    "        for idx, one_center_logits in enumerate(batch_center_logits):\n",
    "            # å…ˆæŠŠè¿™ä¸ªä¸­å¿ƒç‚¹çš„é‚»å±…ç‚¹çš„logitsæå–å‡ºæ¥\n",
    "            certain_neighbor_logits = batch_all_logits[rx_list[idx]]\n",
    "            # è¿›è¡Œç›¸å‡ï¼\n",
    "            distance = torch.abs(certain_neighbor_logits - one_center_logits)[:,0]\n",
    "            howManyNeighbors = distance.shape[0]\n",
    "            undersampledNeighbor = (distance.argsort()[0:int(howManyNeighbors / 2) + 1]).tolist()\n",
    "            # å¯¹rho-è¿›è¡Œæ›´æ–° è¿™ä¸ªæ›´æ–°æœ‰ä»€ä¹ˆæ„ä¹‰å—ï¼Ÿ\n",
    "            self.rho_neg = distance(distance.argsort()[int(howManyNeighbors / 2)])\n",
    "            # rx_list_undersampled.append(nearest50Idx)\n",
    "            # è¿™å°±æ˜¯æˆ‘ä»¬é™é‡‡æ ·ä¹‹åçš„é‚»å±…æ ·æœ¬ï¼Œè¿™é‡Œæ˜¯orderIdx\n",
    "        \n",
    "            # label=1çš„æ—¶å€™æ˜¯å°æ ·æœ¬ï¼\n",
    "            if batch_center_labels[idx] == 1:\n",
    "                # TODO è¿™é‡Œçš„ç»´åº¦è‚¯å®šæœ‰ç‚¹é—®é¢˜\n",
    "                distance2 = torch.abs(train_pos_logits - one_center_logits)[:,0] # è¿™ä¸ªæ—¶å€™å·²ç»flattenäº†\n",
    "                choosedSameClassNode = distance2.argsort()[0:self.avg_half_pos_neigh + 1]\n",
    "\n",
    "            # undersampleä¹‹åçš„orderIdxåœ¨undersampledNeighboré‡Œ\n",
    "            # oversampleä¹‹åçš„orderIdxåœ¨choosedSameClassNodeé‡Œ\n",
    "\n",
    "        \n",
    "\n",
    "    def NeighborhoodSamplerForTest(\n",
    "        self,\n",
    "    ):\n",
    "        pass\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ä¸‰å±‚å…³ç³»äº¤äº’å±‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InterAgg(nn.Module):\n",
    "    \"\"\" \n",
    "    å¯¹ä¸‰å±‚å…³ç³»è¿›è¡Œmessage aggregate\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        # features: torch.Tensor,\n",
    "        feature_dim: int,\n",
    "        output_dim: int,\n",
    "        # adj_lists: defaultdict,\n",
    "        # train_pos_mask: list,\n",
    "        device: torch.device,\n",
    "        num_classes:int = 2,\n",
    "        num_relations:int =3\n",
    "        ) -> None:\n",
    "        super(InterAgg, self).__init__()\n",
    "        # self.features = features\n",
    "        self.feature_dim = feature_dim\n",
    "        self.output_dim = output_dim\n",
    "        # self.adj_lists = adj_lists # 3ä¸ªå…³ç³»çš„defaultdict\n",
    "        # self.train_pos_mask = train_pos_mask\n",
    "        self.device = device\n",
    "        self.num_classes =  num_classes\n",
    "\n",
    "        # ä¸‰ä¸ªå…³ç³»çš„embeddingè¦ç³…åˆæˆä¸€ä¸ªï¼Œéœ€è¦è¿›è¡Œä¸€ä¸ªçº¿æ€§å±‚è½¬æ¢\n",
    "        self.proj = nn.Linear(\n",
    "            in_features=num_relations*self.output_dim + self.feature_dim,\n",
    "            # å…¥ç»´åº¦æ˜¯ä¸‰ä¸ªrealtionçš„embeddingå’ŒåŸç‰¹å¾contactåœ¨ä¸€èµ·çš„\n",
    "            out_features=output_dim\n",
    "        )\n",
    "\n",
    "        # å¯æ˜¯è·ç¦»å‡½æ•°ä¸æ˜¯æ¯ä¸ªå…³ç³»çš„éƒ½ä¸ä¸€æ ·å—ï¼Ÿï¼Ÿ\n",
    "        self.label_linear = nn.Linear(self.feature_dim,self.num_classes)\n",
    "        # è¿™ä¸ªè·ç¦»å‡½æ•°ç”šè‡³åªè¾“å‡ºlogitsï¼Œæ²¡æœ‰è¿›è¡Œsigmoid\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "        # å‡†å¤‡intraAggå±‚\n",
    "        self.intra1 = IntraAgg(\n",
    "            feature_dim=self.feature_dim,\n",
    "            output_dim=self.output_dim,\n",
    "            # avg_half_pos_neigh=self.avg_half_neigh_size[0],\n",
    "            # train_pos_mask=self.train_pos_mask,\n",
    "            device=self.device\n",
    "        )\n",
    "        self.intra2 = IntraAgg(\n",
    "            self.feature_dim,self.output_dim,self.device\n",
    "        )\n",
    "        self.intra3 = IntraAgg(\n",
    "            self.feature_dim,self.output_dim,self.device\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        features: torch.Tensor,\n",
    "        batch_center_mask,\n",
    "        batch_center_label,\n",
    "        train_pos_mask,\n",
    "        adj_lists,\n",
    "        train_flag = True\n",
    "        ):\n",
    "        \"\"\" \n",
    "        :param batch_mask: æœ¬æ‰¹æ¬¡ä¸­è¦è®­ç»ƒçš„ç‚¹\n",
    "        :param batch_label: æœ¬æ‰¹æ¬¡ä¸­è®­ç»ƒç‚¹çš„label\n",
    "        \"\"\"\n",
    "        self.features = features\n",
    "        self.adj_lists = adj_lists\n",
    "        self.train_pos_mask = train_pos_mask\n",
    "\n",
    "        # è®¡ç®—minority classçš„average neighborhood size\n",
    "        avg_half_neigh_size = []\n",
    "        for relationIdx in range(len(self.adj_lists)):\n",
    "            total = 0\n",
    "            for trainIdx in self.train_pos_mask:\n",
    "                total += len(self.adj_lists[relationIdx][trainIdx])\n",
    "            avg_half_neigh_size.append(total / len(self.train_pos_mask))\n",
    "        self.avg_half_neigh_size = avg_half_neigh_size\n",
    "\n",
    "\n",
    "        # batch_maskæ˜¯ä»€ä¹ˆï¼Œæ˜¯æœ¬batchä¸­æ‰€è¦è€ƒå¯Ÿçš„ä¸­å¿ƒç‚¹\n",
    "        # æˆ‘ä»¬åç»­è¦ç”¨åˆ°çš„ä¿¡æ¯åŒ…æ‹¬æœ¬batchçš„ä¸­å¿ƒç‚¹åŠå®ƒä»¬çš„1-hop neighbor\n",
    "        # æ‰€ä»¥æä¸€ä¸ªbatch_all_maskï¼Œå°±åŒ…æ‹¬äº†ä¸Šè¿°è¿™äº›éœ€è¦çš„ç‚¹    \n",
    "        to_neighs = []  # to_neighsé‡Œé¢æœ€ç»ˆå°†ä¼šæ˜¯ä¸‰ä¸ªåˆ—è¡¨ï¼Œæ¯ä¸ªåˆ—è¡¨æ˜¯æŸä¸€ä¸ªå…³ç³»çš„adjlistè½¬æˆåˆ—è¡¨\n",
    "        for adj_list in self.adj_lists:\n",
    "            to_neighs.append([set(adj_list[int(node)]) for node in batch_center_mask])\n",
    "        # to_neighs be like: [[{æŸç‚¹çš„æ‰€æœ‰é‚»å±…},{},...,{}],[],[]]\n",
    "        batch_all_nodes = set.union(set.union(*to_neighs[0]), set.union(*to_neighs[1]),\n",
    "                                 set.union(*to_neighs[2], set(batch_center_mask)))\n",
    "        # batch_all_nodes be like: {0,1,3,4,5,...}\n",
    "        batch_all_mask = list(batch_all_nodes)\n",
    "        # batch_all_mask be like: [0,1,3,4,5,...]\n",
    "        # batch_all_mask å†…æ‰¿è½½äº†æœ¬batchè®­ç»ƒæ‰€éœ€çš„æ‰€æœ‰ç‚¹çš„index -> TODO è¿™ä¸ªindexæ˜¯é’ˆå¯¹è°æ¥è¯´çš„ï¼Ÿ\n",
    "        \n",
    "        # æå–å‡ºæœ¬batch allç‚¹çš„feature\n",
    "        # batch_features = self.features[batch_all_mask]\n",
    "        # æˆ‘å»ï¼Œfeaturesæ˜¯Embeddingå±‚â€¦â€¦\n",
    "        batch_all_features = self.features[torch.LongTensor(batch_all_mask).to(self.device)]\n",
    "        # -> shape (|BatchAll|,feat_dim)\n",
    "        # postive nodes features\n",
    "        pos_features = self.feautres[torch.LongTensor(self.train_pos_mask).to(self.device)]\n",
    "        # -> shape (|Pos|,feat_dim)\n",
    "\n",
    "        # å‡ºäºåŠ å¿«è®¿é—®é€Ÿåº¦çš„è€ƒè™‘ï¼ˆåº”è¯¥æ˜¯ï¼‰ï¼Œdefaultdictæ¶‰åŠåˆ°æŸ¥æ‰¾è¿‡ç¨‹â€”â€”è¿™å¤ªæ…¢å•¦ï¼\n",
    "        # ä½†æ˜¯nodesçš„trainIdxå’Œåœ¨batch_all_maskä¸­çš„orderIdxéœ€è¦è¿›è¡Œç›¸äº’è½¬åŒ–ï¼Œå¯¹å§\n",
    "        trainIdx2orderIdx = {trainIdx : orderIdx for trainIdx, orderIdx in zip(batch_all_nodes, range(len(batch_all_nodes)))}\n",
    "        orderIdx2trainIdx = (lambda d: dict(zip(d.itervalues(),d.iterkeys())))(trainIdx2orderIdx)\n",
    "\n",
    "        # TODO å¯æ˜¯scoreä¸æ˜¯åœ¨æ¯ä¸ªintraå±‚é‡Œå•ç‹¬ç®—çš„å—ï¼Ÿï¼Ÿï¼Ÿ\n",
    "        # å…ˆæŠŠbatch allçš„logitséƒ½ç®—å®Œ\n",
    "        batch_all_logits = self.label_linear(batch_all_features)\n",
    "        # æ³¨æ„åˆ°ï¼Œpos maskä¸­çš„ç‚¹å¾ˆæ˜æ˜¾å¯èƒ½ä¸åœ¨batch allä¸­\n",
    "        pos_logits = self.label_linear(pos_features)\n",
    "\n",
    "        # æå–ä¸€äº›ç‰¹å®šç‚¹çš„logits\n",
    "        # æå–æœ¬batch centerç‚¹çš„logits\n",
    "        batch_center_logits = batch_all_logits[itemgetter(*batch_center_mask)(trainIdx2orderIdx)]\n",
    "\n",
    "        r1_list = [list(to_neigh) for to_neigh in to_neighs[0]]\n",
    "        r2_list = [list(to_neigh) for to_neigh in to_neighs[1]]\n",
    "        r3_list = [list(to_neigh) for to_neigh in to_neighs[2]]\n",
    "        # rx_list: [[æ­¤å…³ç³»ä¸‹æŸä¸ªç‚¹çš„æ‰€æœ‰é‚»å±…],[],[]...,[]]\n",
    "\n",
    "        r1_embeds = self.intra1.forward(\n",
    "            batch_center_mask,\n",
    "            batch_center_label,\n",
    "            self.train_pos_mask,\n",
    "            r1_list,\n",
    "            batch_center_logits,\n",
    "            batch_all_logits,\n",
    "            pos_logits,\n",
    "            trainIdx2orderIdx,\n",
    "            orderIdx2trainIdx,\n",
    "            self.avg_half_neigh_size[0]\n",
    "        )\n",
    "        r2_embeds = self.intra1.forward(\n",
    "            batch_center_mask,\n",
    "            batch_center_label,            \n",
    "            self.train_pos_mask,            \n",
    "            r2_list,\n",
    "            batch_center_logits,\n",
    "            batch_all_logits,\n",
    "            pos_logits,\n",
    "            trainIdx2orderIdx,\n",
    "            orderIdx2trainIdx,\n",
    "            self.avg_half_neigh_size[1]\n",
    "        )\n",
    "        r3_embeds = self.intra1.forward(\n",
    "            batch_center_mask,\n",
    "            batch_center_label,\n",
    "            self.train_pos_mask,\n",
    "            r3_list,\n",
    "            batch_center_logits,\n",
    "            batch_all_logits,\n",
    "            pos_logits,\n",
    "            trainIdx2orderIdx,\n",
    "            orderIdx2trainIdx,\n",
    "            self.avg_half_neigh_size[2]\n",
    "        )\n",
    "        # rx_embeds -> (|B|,out_dim)\n",
    "        all_relation_and_self_embeds = torch.cat([self.features[batch_center_mask],r1_embeds,r2_embeds,r3_embeds],dim=1)\n",
    "        proj_all_embeds = F.relu(self.proj(all_relation_and_self_embeds))\n",
    "\n",
    "        return proj_all_embeds, batch_center_logits\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PC-GNNæ¶ˆæ¯ä¼ é€’"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PCGNN(nn.Module):\n",
    "    \"\"\" \n",
    "    ä¸€å±‚PC-GNNç”¨ä»¥message passing -> æ ¸å¿ƒç‰¹ç‚¹æ˜¯ï¼Œå±…ç„¶éœ€è¦label=ã€‚= \\\\\n",
    "    è®ºæ–‡æºä»£ç å±…ç„¶ç›´æ¥æŠŠä¸€å±‚å½“æ•´ä¸ªæ¨¡å‹äº†â€¦â€¦å¥½ğŸ•å•Š\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self, \n",
    "        in_channels: int, \n",
    "        out_channels: int,\n",
    "        # adj_lists: List[defaultdict],\n",
    "        # train_pos_mask: list,\n",
    "        device: torch.device,\n",
    "        normalize = True,\n",
    "        num_classes: int = 2,\n",
    "        bias = False, \n",
    "    ):  \n",
    "        \"\"\"\n",
    "        ä¸€å±‚Pick&Choose çš„ message passager \\\\\n",
    "        éš¾é“interå±‚ä¸åº”è¯¥åœ¨è¿™é‡Œè¿›è¡Œå£°æ˜å—â€¦â€¦ \\\\\n",
    "        :param in_channels: è¾“å…¥çš„ç‰¹å¾ç»´æ•°\n",
    "        :param out_channels: è¾“å‡ºçš„ç‰¹å¾ç»´æ•°\n",
    "        :param num_classes: æœ€åéœ€è¦åšèŠ‚ç‚¹åˆ†ç±»çš„ç±»æ•°\n",
    "        \"\"\"\n",
    "        super(PCGNN, self).__init__()\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.normalize = normalize\n",
    "        self.interAgg = InterAgg(\n",
    "            feature_dim=in_channels,\n",
    "            output_dim=out_channels,\n",
    "            # adj_lists=adj_lists,\n",
    "            # train_pos_mask=train_pos_mask,\n",
    "            device=device\n",
    "        )\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        # self.lin_l.reset_parameters()\n",
    "        # self.lin_r.reset_parameters()\n",
    "        pass\n",
    "\n",
    "    def forward(self, features ,labels, batch_mask, train_pos_mask, adj_lists, train_flag = True):\n",
    "        \"\"\"\n",
    "        :param features: (|N|, input_channels)\n",
    "        :param labels: (|N|,)\n",
    "        :param batch_mask: (|B|,)åœ¨æ­¤æ¬¡è¿‡ç¨‹ä¸­éœ€è¦è€ƒå¯Ÿçš„ä¸­å¿ƒç‚¹çš„mask\n",
    "        :param train_pos_mask:\n",
    "        :param adj_lists:\n",
    "        :return output_embeds: (|B|,out_dim)\n",
    "        :return label_scores: (|B|,2)\n",
    "        \"\"\"\n",
    "\n",
    "        embeds, logits = self.interAgg(\n",
    "            features=features,\n",
    "            batch_center_mask=batch_mask,\n",
    "            batch_center_label=labels[batch_mask],\n",
    "            train_pos_mask=train_pos_mask,\n",
    "            adj_lists=adj_lists\n",
    "        )\n",
    "\n",
    "        return embeds, logits\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ä¸€ä¸ªargså®ä¾‹ï¼š\n",
    "\n",
    "{'model_type': 'GraphSage', 'dataset': 'cora', 'num_layers': 2, 'heads': 1, 'batch_size': 32, 'hidden_dim': 32,\n",
    "        'dropout': 0.5, 'epochs': 500, 'opt': 'adam', 'opt_scheduler': 'none', 'opt_restart': 0, 'weight_decay': 5e-3, 'lr': 0.01},"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GNNStack èŒƒå¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNNStack(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        input_dim : int, \n",
    "        hidden_dim: int,\n",
    "        output_dim : int,\n",
    "        device: torch.device,\n",
    "        num_classes : int = 2,\n",
    "        num_layers : int = 1,\n",
    "        dropout : float = 0.5, \n",
    "        heads : int = 1,\n",
    "        model_type : str = 'PCGNN',\n",
    "        emb : bool = False\n",
    "        ) -> None:\n",
    "        super(GNNStack, self).__init__()\n",
    "\n",
    "        conv_model = self.build_conv_model(model_type)\n",
    "        # self.convs = nn.ModuleList()\n",
    "        # self.convs.append(conv_model(\n",
    "        #     in_channels=input_dim,\n",
    "        #     out_channels=hidden_dim\n",
    "        # ))\n",
    "        assert (num_layers >= 1), 'Number of layers is not >=1'\n",
    "        if num_layers == 1:\n",
    "            self.convs = conv_model(\n",
    "                in_channels=input_dim,\n",
    "                out_channels=output_dim,\n",
    "                device=device\n",
    "            )\n",
    "        else: \n",
    "            # for l in range(num_layers):\n",
    "            #     if l == 0:\n",
    "            #         self.convs.append(conv_model(input_dim,hidden_dim))\n",
    "            #     elif l == num_layers-1:\n",
    "            #         self.convs.append(conv_model(heads*hidden_dim,output_dim))\n",
    "            #     else:\n",
    "            #         self.convs.append(conv_model(heads*hidden_dim, hidden_dim))\n",
    "            raise NotImplementedError\n",
    "\n",
    "        # # post-message-passing\n",
    "        # self.post_mp = nn.Sequential(\n",
    "        #     nn.Linear(heads * hidden_dim, hidden_dim), nn.Dropout(self.dropout), \n",
    "        #     nn.Linear(hidden_dim, output_dim))\n",
    "        # # å—¯â€¦â€¦å…¶å®æˆ‘ä¸€å…±è®¾äº†num_layers+1å±‚\n",
    "\n",
    "        # PCGNNæœ€åè¿˜æœ‰ä¸€ä¸ªçº¿æ€§å±‚ç”¨äºnodeåˆ†ç±»ï¼\n",
    "        self.final_proj = nn.Linear(output_dim,num_classes)\n",
    "\n",
    "        self.dropout = dropout\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.emb = emb\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    def build_conv_model(self, model_type):\n",
    "        if model_type == 'PCGNN':\n",
    "            return PCGNN\n",
    "        else: \n",
    "            raise NotImplementedError\n",
    "\n",
    "    def forward(self, features, labels, batch_mask, train_pos_mask, adj_lists):\n",
    "        \"\"\" \n",
    "        :param features: æ‰€æœ‰ç‚¹çš„features\n",
    "        :param labels: æ‰€æœ‰ç‚¹çš„label\n",
    "        :param batch_mask: æœ¬æ‰¹æ¬¡ç‚¹çš„mask æˆ–è€…æ˜¯ä¹‹åtest/validçš„æ—¶å€™çš„mask\n",
    "        :param train_pos_mask:\n",
    "        :param adj_lists:\n",
    "        \"\"\"\n",
    "        # x, edge_index, batch = data.x, data.edge_index, data.batch        \n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "            embeds, logits = self.convs(features,labels,batch_mask,train_pos_mask,adj_lists)\n",
    "            # x = F.relu(x)\n",
    "            # x = F.dropout(x, p=self.dropout,training=self.training)\n",
    "\n",
    "        # x = self.post_mp(x)\n",
    "        if self.emb == True:\n",
    "            return embeds\n",
    "\n",
    "        return embeds, logits\n",
    "\n",
    "    def loss(self, features, labels, batch_mask, train_pos_mask, adj_lists):\n",
    "        \"\"\" \n",
    "        PCGNNçš„lossåŒ…æ‹¬ä¸¤ä¸ª:loss_{gnn}å’Œloss_{dist}\n",
    "        \"\"\"\n",
    "        embeds,logits = self.forward(\n",
    "            features=features,\n",
    "            labels=labels,\n",
    "            batch_mask=batch_mask,\n",
    "            train_pos_mask=train_pos_mask,\n",
    "            adj_lists=adj_lists            \n",
    "        )\n",
    "\n",
    "        # PCGNNæœ‰ä¸¤ä¸ªloss\n",
    "        # loss_{gnn}\n",
    "        gnn_pred = self.final_proj(embeds)\n",
    "        gnn_loss = self.criterion(gnn_pred,labels[batch_mask].squeeze())\n",
    "\n",
    "        # loss_{dist}\n",
    "        dist_loss = self.criterion(logits,labels[batch_mask].squeeze())\n",
    "\n",
    "        return gnn_loss + dist_loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizeræ„å»º"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_optimizer(args, params):\n",
    "    weight_decay = args.weight_decay\n",
    "    filter_fn = filter(lambda p: p.requires_grad, params)\n",
    "    if args.opt == 'adam':\n",
    "        optimizer = optim.Adam(filter_fn, lr=args.lr,\n",
    "                               weight_decay=weight_decay)\n",
    "    elif args.opt == 'sgd':\n",
    "        optimizer = optim.SGD(filter_fn, lr=args.lr,\n",
    "                              momentum=0.95, weight_decay=weight_decay)\n",
    "    elif args.opt == 'rmsprop':\n",
    "        optimizer = optim.RMSprop(\n",
    "            filter_fn, lr=args.lr, weight_decay=weight_decay)\n",
    "    elif args.opt == 'adagrad':\n",
    "        optimizer = optim.Adagrad(\n",
    "            filter_fn, lr=args.lr, weight_decay=weight_decay)\n",
    "    if args.opt_scheduler == 'none':\n",
    "        return None, optimizer\n",
    "    elif args.opt_scheduler == 'step':\n",
    "        scheduler = optim.lr_scheduler.StepLR(\n",
    "            optimizer, step_size=args.opt_decay_step, gamma=args.opt_decay_rate)\n",
    "    elif args.opt_scheduler == 'cos':\n",
    "        scheduler = optim.lr_scheduler.CosineAnnealingLR(\n",
    "            optimizer, T_max=args.opt_restart)\n",
    "    return scheduler, optimizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ä¸€ä¸ªargså®ä¾‹ï¼š\n",
    "\n",
    "{'model_type': 'GraphSage', 'dataset': 'cora', 'num_layers': 2, 'heads': 1, 'batch_size': 32, 'hidden_dim': 32,\n",
    "        'dropout': 0.5, 'epochs': 500, 'opt': 'adam', 'opt_scheduler': 'none', 'opt_restart': 0, 'weight_decay': 5e-3, 'lr': 0.01},"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "HeteroData(\n",
      "  homo=[11944],\n",
      "  \u001b[1mreview\u001b[0m={\n",
      "    x=[11944, 25],\n",
      "    y=[11944],\n",
      "    train_mask=[3455],\n",
      "    valid_mask=[1710],\n",
      "    test_mask=[3474]\n",
      "  },\n",
      "  \u001b[1m(review, r1, review)\u001b[0m={\n",
      "    adj=[11944, 11944],\n",
      "    adj_list=[11944],\n",
      "    edge_index=[2, 351216]\n",
      "  },\n",
      "  \u001b[1m(review, r2, review)\u001b[0m={\n",
      "    adj=[11944, 11944],\n",
      "    adj_list=[11944],\n",
      "    edge_index=[2, 7132958]\n",
      "  },\n",
      "  \u001b[1m(review, r3, review)\u001b[0m={\n",
      "    adj=[11944, 11944],\n",
      "    adj_list=[11944],\n",
      "    edge_index=[2, 2073474]\n",
      "  }\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "def show_data(dataset_name:str = 'Amazon'):\n",
    "    # print(f\"Node Classification. test set size: {graph.ndata['train_mask'].sum().item()}\")\n",
    "    print()\n",
    "\n",
    "    data = constructPyGHeteroData(dataset_name)\n",
    "    # dataæ˜¯ä¸€ä¸ªheterogeneouså›¾ï¼Œä¸€ç§èŠ‚ç‚¹ï¼Œä¸‰ç§å…³ç³»\n",
    "    print(data)\n",
    "\n",
    "\n",
    "train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCGNNæ¨¡å‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelHandler():\n",
    "\n",
    "    def __init__(\n",
    "        self, \n",
    "        data: HeteroData,\n",
    "        data_name:str = 'Amazon',\n",
    "        random_seed:int = 42,\n",
    "        use_cuda:bool = True,\n",
    "        opt:str = 'adam',\n",
    "        weight_decay:float = 5e-3,\n",
    "        lr:float = 0.01,\n",
    "        dropout:float = 0.5,\n",
    "        num_layers:int = 2,\n",
    "        num_epochs:int = 50,\n",
    "        batch_size:int = 256\n",
    "        ) -> None:\n",
    "        np.random.seed(random_seed)\n",
    "        torch.manual_seed(random_seed)\n",
    "\n",
    "        # preprare data\n",
    "        self.data = data\n",
    "        # å…³äºæ­¤æ•°æ®é›†æœ‰ä¸ªå¾ˆé‡è¦çš„äº‹ï¼Œå³ï¼Œnodeæ•°æ®éƒ½æ˜¯ndarrayæ ¼å¼ï¼Œrelationçš„æ•°æ®éƒ½æ˜¯tensorï¼\n",
    "        # TODO normlize feature??\n",
    "\n",
    "        if use_cuda and torch.cuda.is_available():\n",
    "            self.device = torch.device('cuda:0')\n",
    "        else:\n",
    "            self.device = torch.device('cpu')\n",
    "\n",
    "        self.opt, self.weight_decay,self.lr = opt,weight_decay,lr\n",
    "        self.num_epochs = num_epochs\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def train(self):\n",
    "        feat_data,label_data = self.data['review'].x,self.data['review'].y\n",
    "        train_mask,valid_mask,test_mask = self.data['review'].train_mask,self.data['review'].valid_mask,self.data['review'].test_mask\n",
    "        train_pos_mask = self.data['review'].train_pos_mask\n",
    "        adj_lists = [\n",
    "            self.data['review','r1','review'].adj_list[0],\n",
    "            self.data['review','r2','review'].adj_list[0],\n",
    "            self.data['review','r3','review'].adj_list[0],\n",
    "        ]\n",
    "\n",
    "        features = nn.Embedding(feat_data.shape[0], feat_data.shape[1])\n",
    "        features.weight = nn.Parameter(torch.FloatTensor(feat_data), requires_grad=False).to(self.device)\n",
    "\n",
    "        # æˆ‘ä»¬åªä½¿ç”¨PCGNN\n",
    "        GNN = GNNStack(\n",
    "            input_dim=feat_data.shape[1],\n",
    "            hidden_dim=64,\n",
    "            output_dim=64,\n",
    "            device=self.device\n",
    "        )\n",
    "\n",
    "        # optimizer\n",
    "        if(self.opt == 'adam'):\n",
    "            optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, GNN.parameters()), lr=self.lr, weight_decay=self.weight_decay)\n",
    "        else:\n",
    "            raise NotImplementedError(\"This optimizer is not implemented yet.\")\n",
    "        \n",
    "        for epoch in tqdm(range(self.num_epochs)):\n",
    "            # Pické˜¶æ®µï¼Œå€ŸåŠ©labelBalancedSamplerè¿›è¡Œä¸€ä¸ªé™é‡‡æ ·\n",
    "            train_mask = LabelBalancedSampler(train_mask,label_data[train_mask],self.data['homo_adj_list'][0],)\n",
    "            # è¿™é‡Œçš„train maskæ˜¯ç»è¿‡æ¦‚ç‡pickè¿‡çš„ï¼\n",
    "\n",
    "            # æˆ‘ä»¬åœ¨å‡†å¤‡æ•°æ®é›†æ—¶å·²ç»å‡†å¤‡å¥½äº†train_pos/neg_mask\n",
    "            num_batches = int(len(train_mask) / self.batch_size) + 1\n",
    "\n",
    "            loss = 0.\n",
    "\n",
    "            # å¼€å§‹batchè®­ç»ƒ\n",
    "            for batch in range(num_batches):\n",
    "                ind_start = batch*self.batch_size\n",
    "                ind_end = min(batch*self.batch_size,len(train_mask))\n",
    "                batch_nodes_mask = train_mask[ind_start:ind_end]\n",
    "                # batch_label = label_data[batch_nodes_mask]\n",
    "                # TODO è¿™é‡Œçš„ç±»å‹å¯èƒ½å­˜åœ¨é—®é¢˜\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                loss = GNN.loss(\n",
    "                    features=feat_data,\n",
    "                    labels=label_data,\n",
    "                    batch_mask=batch_nodes_mask,\n",
    "                    train_pos_mask=train_pos_mask,\n",
    "                    adj_lists=adj_lists\n",
    "                )\n",
    "\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                loss += loss.item()\n",
    "\n",
    "                print(f'Epoch: {epoch}, loss: {loss.item() / num_batches}')\n",
    "                \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "å¼€å§‹æ¼«æ¼«debugâ€¦â€¦"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import models\n",
    "from myutils import constructPyGHeteroData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = constructPyGHeteroData()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idx=0, len(rx_list[idx])=7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32md:\\Univ\\dl-papers\\PC-GNN-reproduction\\PC_GNN.ipynb Cell 26\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Univ/dl-papers/PC-GNN-reproduction/PC_GNN.ipynb#X34sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model \u001b[39m=\u001b[39m models\u001b[39m.\u001b[39mModelHandler(data)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Univ/dl-papers/PC-GNN-reproduction/PC_GNN.ipynb#X34sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m model\u001b[39m.\u001b[39;49mtrain()\n",
      "File \u001b[1;32md:\\Univ\\dl-papers\\PC-GNN-reproduction\\models.py:275\u001b[0m, in \u001b[0;36mModelHandler.train\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    271\u001b[0m \u001b[39m# batch_label = label_data[batch_nodes_mask]\u001b[39;00m\n\u001b[0;32m    272\u001b[0m \u001b[39m# TODO è¿™é‡Œçš„ç±»å‹å¯èƒ½å­˜åœ¨é—®é¢˜\u001b[39;00m\n\u001b[0;32m    274\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m--> 275\u001b[0m loss \u001b[39m=\u001b[39m GNN\u001b[39m.\u001b[39;49mloss(\n\u001b[0;32m    276\u001b[0m     features\u001b[39m=\u001b[39;49mfeat_data,\n\u001b[0;32m    277\u001b[0m     labels\u001b[39m=\u001b[39;49mlabel_data,\n\u001b[0;32m    278\u001b[0m     batch_mask\u001b[39m=\u001b[39;49mbatch_nodes_mask,\n\u001b[0;32m    279\u001b[0m     train_pos_mask\u001b[39m=\u001b[39;49mtrain_pos_mask,\n\u001b[0;32m    280\u001b[0m     adj_lists\u001b[39m=\u001b[39;49madj_lists\n\u001b[0;32m    281\u001b[0m )\n\u001b[0;32m    283\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n\u001b[0;32m    284\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n",
      "File \u001b[1;32md:\\Univ\\dl-papers\\PC-GNN-reproduction\\models.py:170\u001b[0m, in \u001b[0;36mGNNStack.loss\u001b[1;34m(self, features, labels, batch_mask, train_pos_mask, adj_lists)\u001b[0m\n\u001b[0;32m    166\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mloss\u001b[39m(\u001b[39mself\u001b[39m, features, labels, batch_mask, train_pos_mask, adj_lists):\n\u001b[0;32m    167\u001b[0m     \u001b[39m\"\"\" \u001b[39;00m\n\u001b[0;32m    168\u001b[0m \u001b[39m    PCGNNçš„lossåŒ…æ‹¬ä¸¤ä¸ª:loss_{gnn}å’Œloss_{dist}\u001b[39;00m\n\u001b[0;32m    169\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 170\u001b[0m     embeds, logits \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(\n\u001b[0;32m    171\u001b[0m         features\u001b[39m=\u001b[39;49mfeatures,\n\u001b[0;32m    172\u001b[0m         labels\u001b[39m=\u001b[39;49mlabels,\n\u001b[0;32m    173\u001b[0m         batch_mask\u001b[39m=\u001b[39;49mbatch_mask,\n\u001b[0;32m    174\u001b[0m         train_pos_mask\u001b[39m=\u001b[39;49mtrain_pos_mask,\n\u001b[0;32m    175\u001b[0m         adj_lists\u001b[39m=\u001b[39;49madj_lists\n\u001b[0;32m    176\u001b[0m     )\n\u001b[0;32m    178\u001b[0m     \u001b[39m# PCGNNæœ‰ä¸¤ä¸ªloss\u001b[39;00m\n\u001b[0;32m    179\u001b[0m     \u001b[39m# loss_{gnn}\u001b[39;00m\n\u001b[0;32m    180\u001b[0m     gnn_pred \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfinal_proj(embeds)\n",
      "File \u001b[1;32md:\\Univ\\dl-papers\\PC-GNN-reproduction\\models.py:155\u001b[0m, in \u001b[0;36mGNNStack.forward\u001b[1;34m(self, features, labels, batch_mask, train_pos_mask, adj_lists)\u001b[0m\n\u001b[0;32m    152\u001b[0m \u001b[39m# x, edge_index, batch = data.x, data.edge_index, data.batch\u001b[39;00m\n\u001b[0;32m    154\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_layers):\n\u001b[1;32m--> 155\u001b[0m     embeds, logits \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconvs(\n\u001b[0;32m    156\u001b[0m         features, labels, batch_mask, train_pos_mask, adj_lists)\n\u001b[0;32m    157\u001b[0m     \u001b[39m# x = F.relu(x)\u001b[39;00m\n\u001b[0;32m    158\u001b[0m     \u001b[39m# x = F.dropout(x, p=self.dropout,training=self.training)\u001b[39;00m\n\u001b[0;32m    159\u001b[0m \n\u001b[0;32m    160\u001b[0m \u001b[39m# x = self.post_mp(x)\u001b[39;00m\n\u001b[0;32m    161\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39memb \u001b[39m==\u001b[39m \u001b[39mTrue\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\bin\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32md:\\Univ\\dl-papers\\PC-GNN-reproduction\\models.py:73\u001b[0m, in \u001b[0;36mPCGNN.forward\u001b[1;34m(self, features, labels, batch_mask, train_pos_mask, adj_lists, train_flag)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, features, labels, batch_mask, train_pos_mask, adj_lists, train_flag\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m     63\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39m    :param features: (|N|, input_channels)\u001b[39;00m\n\u001b[0;32m     65\u001b[0m \u001b[39m    :param labels: (|N|,)\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[39m    :return label_scores: (|B|,2)\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 73\u001b[0m     embeds, logits \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minterAgg(\n\u001b[0;32m     74\u001b[0m         features\u001b[39m=\u001b[39;49mfeatures,\n\u001b[0;32m     75\u001b[0m         batch_center_mask\u001b[39m=\u001b[39;49mbatch_mask,\n\u001b[0;32m     76\u001b[0m         batch_center_label\u001b[39m=\u001b[39;49mlabels[batch_mask],\n\u001b[0;32m     77\u001b[0m         train_pos_mask\u001b[39m=\u001b[39;49mtrain_pos_mask,\n\u001b[0;32m     78\u001b[0m         adj_lists\u001b[39m=\u001b[39;49madj_lists\n\u001b[0;32m     79\u001b[0m     )\n\u001b[0;32m     81\u001b[0m     \u001b[39mreturn\u001b[39;00m embeds, logits\n",
      "File \u001b[1;32mc:\\Users\\bin\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32md:\\Univ\\dl-papers\\PC-GNN-reproduction\\agg.py:305\u001b[0m, in \u001b[0;36mInterAgg.forward\u001b[1;34m(self, features, batch_center_mask, batch_center_label, train_pos_mask, adj_lists, train_flag)\u001b[0m\n\u001b[0;32m    302\u001b[0m r3_list \u001b[39m=\u001b[39m [\u001b[39mlist\u001b[39m(to_neigh) \u001b[39mfor\u001b[39;00m to_neigh \u001b[39min\u001b[39;00m to_neighs[\u001b[39m2\u001b[39m]]\n\u001b[0;32m    303\u001b[0m \u001b[39m# rx_list: [[æ­¤å…³ç³»ä¸‹æŸä¸ªç‚¹çš„æ‰€æœ‰é‚»å±…],[],[]...,[]]\u001b[39;00m\n\u001b[1;32m--> 305\u001b[0m r1_embeds \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mintra1\u001b[39m.\u001b[39;49mforward(\n\u001b[0;32m    306\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfeatures,\n\u001b[0;32m    307\u001b[0m     batch_center_mask,\n\u001b[0;32m    308\u001b[0m     batch_center_label,\n\u001b[0;32m    309\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_pos_mask,\n\u001b[0;32m    310\u001b[0m     r1_list,\n\u001b[0;32m    311\u001b[0m     batch_center_logits,\n\u001b[0;32m    312\u001b[0m     batch_all_logits,\n\u001b[0;32m    313\u001b[0m     pos_logits,\n\u001b[0;32m    314\u001b[0m     trainIdx2orderIdx,\n\u001b[0;32m    315\u001b[0m     orderIdx2trainIdx,\n\u001b[0;32m    316\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mavg_half_neigh_size[\u001b[39m0\u001b[39;49m]\n\u001b[0;32m    317\u001b[0m )\n\u001b[0;32m    318\u001b[0m r2_embeds \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mintra1\u001b[39m.\u001b[39mforward(\n\u001b[0;32m    319\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeatures,\n\u001b[0;32m    320\u001b[0m     batch_center_mask,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    329\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mavg_half_neigh_size[\u001b[39m1\u001b[39m]\n\u001b[0;32m    330\u001b[0m )\n\u001b[0;32m    331\u001b[0m r3_embeds \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mintra1\u001b[39m.\u001b[39mforward(\n\u001b[0;32m    332\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeatures,\n\u001b[0;32m    333\u001b[0m     batch_center_mask,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    342\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mavg_half_neigh_size[\u001b[39m2\u001b[39m]\n\u001b[0;32m    343\u001b[0m )\n",
      "File \u001b[1;32md:\\Univ\\dl-papers\\PC-GNN-reproduction\\agg.py:124\u001b[0m, in \u001b[0;36mIntraAgg.forward\u001b[1;34m(self, features, batch_center_mask, batch_center_labels, train_pos_mask, rx_list, batch_center_logits, batch_all_logits, train_pos_logits, trainIdx2OrderIdx, orderIdx2trainIdx, avg_half_pos_neigh, train_flag)\u001b[0m\n\u001b[0;32m    119\u001b[0m agg_feats \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mmean(neighbor_feats, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[0;32m    121\u001b[0m \u001b[39m# æŠŠå’Œä¸­å¿ƒèŠ‚ç‚¹çš„featè¿›è¡Œcontact\u001b[39;00m\n\u001b[0;32m    122\u001b[0m \u001b[39m# æ³¨æ„æœ‰ä¸€ä¸ªreshapeï¼\u001b[39;00m\n\u001b[0;32m    123\u001b[0m contacted_feat \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat(\n\u001b[1;32m--> 124\u001b[0m     [features[trainIdx2OrderIdx[idx]], agg_feats], axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\u001b[39m.\u001b[39mreshape(\u001b[39m1\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m    125\u001b[0m \u001b[39m# shape: (1,2*h_{l-1})\u001b[39;00m\n\u001b[0;32m    126\u001b[0m \n\u001b[0;32m    127\u001b[0m \u001b[39m# è¿›è¡Œçº¿æ€§æ˜ å°„\u001b[39;00m\n\u001b[0;32m    128\u001b[0m out_feats\u001b[39m.\u001b[39mappend(F\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mproj(contacted_feat)))\n",
      "\u001b[1;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "model = models.ModelHandler(data)\n",
    "model.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b03cd7f13856fb3b521b8bb7c9e86e32af68550ba3f54aa9b7b683fd8765685a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
